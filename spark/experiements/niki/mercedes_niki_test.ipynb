{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and inits\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_131\"; Java(TM) SE Runtime Environment (build 1.8.0_131-b11); Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)\n",
      "  Starting server from /Users/niki/anaconda/lib/python3.5/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/z2/4db2w2591kb96lzzxlxwnljm0000gp/T/tmpww0kuf6m\n",
      "  JVM stdout: /var/folders/z2/4db2w2591kb96lzzxlxwnljm0000gp/T/tmpww0kuf6m/h2o_niki_started_from_python.out\n",
      "  JVM stderr: /var/folders/z2/4db2w2591kb96lzzxlxwnljm0000gp/T/tmpww0kuf6m/h2o_niki_started_from_python.err\n"
     ]
    },
    {
     "ename": "H2OServerError",
     "evalue": "Server wasn't able to start in 10.115989 seconds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(url, ip, port, https, insecure, username, password, cookies, proxy, start_h2o, nthreads, ice_root, enable_assertions, max_mem_size, min_mem_size, strict_version_check, ignore_config, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m                                      _msgs=(\"Checking whether there is an H2O instance running at {url}\",\n\u001b[0;32m--> 250\u001b[0;31m                                             \"connected.\", \"not found.\"))\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mH2OConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(server, url, ip, port, https, auth, verify_ssl_certificates, proxy, cookies, verbose, _msgs)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;31m# If a server is unable to respond within 1s, it should be considered a bug. However we disable this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_test_connection\u001b[0;34m(self, max_retries, messages)\u001b[0m\n\u001b[1;32m    587\u001b[0m             raise H2OConnectionError(\"Could not establish link to the H2O cloud %s after %d retries\\n%s\"\n\u001b[0;32m--> 588\u001b[0;31m                                      % (self._base_url, max_retries, \"\\n\".join(errors)))\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OConnectionError\u001b[0m: Could not establish link to the H2O cloud http://localhost:54321 after 5 retries\n[57:01.32] H2OConnectionError: Timeout after 3.042s\n[57:04.54] H2OConnectionError: Timeout after 3.015s\n[57:07.75] H2OConnectionError: Timeout after 3.011s\n[57:10.97] H2OConnectionError: Timeout after 3.008s\n[57:14.18] H2OConnectionError: Timeout after 3.008s",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mH2OServerError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-562c02529ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mH2OXGBoostEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstackedensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mH2OStackedEnsembleEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# give h2o as much memory as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# turn off h2o progress bars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(url, ip, port, https, insecure, username, password, cookies, proxy, start_h2o, nthreads, ice_root, enable_assertions, max_mem_size, min_mem_size, strict_version_check, ignore_config, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstart_h2o\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         hs = H2OLocalServer.start(nthreads=nthreads, enable_assertions=enable_assertions, max_mem_size=mmax,\n\u001b[0;32m--> 257\u001b[0;31m                                   min_mem_size=mmin, ice_root=ice_root, port=port)\n\u001b[0m\u001b[1;32m    258\u001b[0m         h2oconn = H2OConnection.open(server=hs, https=https, verify_ssl_certificates=not insecure,\n\u001b[1;32m    259\u001b[0m                                      auth=auth, proxy=proxy,cookies=cookies, verbose=True)\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/h2o/backend/server.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(jar_path, nthreads, enable_assertions, max_mem_size, min_mem_size, ice_root, port, verbose)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attempting to start a local H2O server...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         hs._launch_server(port=port, baseport=baseport, nthreads=int(nthreads), ea=enable_assertions,\n\u001b[0;32m--> 117\u001b[0;31m                           mmax=max_mem_size, mmin=min_mem_size)\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Server is running at %s://%s:%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/h2o/backend/server.py\u001b[0m in \u001b[0;36m_launch_server\u001b[0;34m(self, port, baseport, mmax, mmin, ea, nthreads)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mgiveup_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgiveup_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TIME_TO_START\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mH2OServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Server wasn't able to start in %f seconds.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OServerError\u001b[0m: Server wasn't able to start in 10.115989 seconds."
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator \n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch \n",
    "from h2o.estimators.xgboost import H2OXGBoostEstimator\n",
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "h2o.init() # give h2o as much memory as possible\n",
    "h2o.no_progress() # turn off h2o progress bars\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 378)\n",
      "(4209, 378)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = h2o.import_file('/Users/niki/Documents/Machine Learning/train.csv')\n",
    "test = h2o.import_file('/Users/niki/Documents/Machine Learning/test.csv')\n",
    "\n",
    "# bug fix - from Keston\n",
    "dummy_col = np.random.rand(test.shape[0])\n",
    "test = test.cbind(h2o.H2OFrame(dummy_col))\n",
    "cols = test.columns\n",
    "cols[-1] = 'y'\n",
    "test.columns = cols\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine data types\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_type_lists(frame=train, rejects=['ID', 'y']):\n",
    "\n",
    "    \"\"\"Creates lists of numeric and categorical variables.\n",
    "    \n",
    "    :param frame: The frame from which to determine types.\n",
    "    :param rejects: Variable names not to be included in returned lists.\n",
    "    :return: Tuple of lists for numeric and categorical variables in the frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    nums, cats = [], []\n",
    "    for key, val in frame.types.items():\n",
    "        if key not in rejects:\n",
    "            if val == 'enum':\n",
    "                cats.append(key)\n",
    "            else: \n",
    "                nums.append(key)\n",
    "                \n",
    "    print('Numeric =', nums)                \n",
    "    print()\n",
    "    print('Categorical =', cats)\n",
    "    \n",
    "    return nums, cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric = ['X282', 'X309', 'X354', 'X53', 'X125', 'X64', 'X340', 'X257', 'X44', 'X51', 'X30', 'X215', 'X278', 'X159', 'X54', 'X225', 'X363', 'X382', 'X375', 'X190', 'X385', 'X145', 'X367', 'X252', 'X383', 'X113', 'X243', 'X129', 'X287', 'X348', 'X50', 'X65', 'X89', 'X192', 'X176', 'X10', 'X11', 'X236', 'X93', 'X244', 'X67', 'X319', 'X31', 'X196', 'X352', 'X263', 'X164', 'X261', 'X302', 'X172', 'X339', 'X146', 'X63', 'X377', 'X245', 'X171', 'X182', 'X62', 'X280', 'X345', 'X324', 'X298', 'X364', 'X61', 'X189', 'X249', 'X266', 'X79', 'X177', 'X207', 'X71', 'X140', 'X365', 'X308', 'X237', 'X73', 'X133', 'X284', 'X267', 'X291', 'X358', 'X213', 'X161', 'X95', 'X233', 'X183', 'X380', 'X344', 'X66', 'X226', 'X162', 'X353', 'X219', 'X325', 'X346', 'X217', 'X123', 'X134', 'X356', 'X264', 'X314', 'X150', 'X242', 'X60', 'X57', 'X180', 'X87', 'X378', 'X32', 'X18', 'X126', 'X272', 'X155', 'X311', 'X260', 'X151', 'X323', 'X293', 'X212', 'X275', 'X351', 'X34', 'X256', 'X36', 'X271', 'X341', 'X370', 'X371', 'X107', 'X205', 'X78', 'X258', 'X283', 'X52', 'X203', 'X154', 'X55', 'X17', 'X241', 'X117', 'X49', 'X77', 'X103', 'X42', 'X210', 'X138', 'X200', 'X163', 'X228', 'X206', 'X197', 'X373', 'X101', 'X33', 'X167', 'X321', 'X306', 'X69', 'X286', 'X132', 'X259', 'X254', 'X277', 'X84', 'X229', 'X120', 'X46', 'X369', 'X230', 'X158', 'X238', 'X144', 'X86', 'X310', 'X240', 'X74', 'X216', 'X22', 'X175', 'X184', 'X179', 'X222', 'X329', 'X374', 'X199', 'X38', 'X220', 'X379', 'X312', 'X317', 'X255', 'X211', 'X202', 'X285', 'X47', 'X108', 'X94', 'X334', 'X19', 'X305', 'X337', 'X12', 'X342', 'X301', 'X83', 'X181', 'X112', 'X124', 'X14', 'X110', 'X165', 'X331', 'X268', 'X122', 'X316', 'X313', 'X174', 'X338', 'X114', 'X48', 'X187', 'X198', 'X253', 'X153', 'X16', 'X91', 'X209', 'X231', 'X118', 'X160', 'X322', 'X166', 'X92', 'X194', 'X360', 'X204', 'X270', 'X111', 'X147', 'X13', 'X347', 'X262', 'X372', 'X156', 'X186', 'X128', 'X333', 'X327', 'X185', 'X368', 'X99', 'X29', 'X218', 'X137', 'X279', 'X269', 'X141', 'X361', 'X315', 'X97', 'X214', 'X288', 'X115', 'X326', 'X80', 'X289', 'X168', 'X304', 'X142', 'X43', 'X292', 'X359', 'X100', 'X135', 'X139', 'X20', 'X105', 'X357', 'X28', 'X294', 'X35', 'X273', 'X143', 'X82', 'X250', 'X81', 'X234', 'X40', 'X104', 'X290', 'X296', 'X300', 'X335', 'X23', 'X109', 'X157', 'X59', 'X131', 'X384', 'X307', 'X39', 'X227', 'X75', 'X88', 'X224', 'X320', 'X276', 'X21', 'X15', 'X251', 'X116', 'X248', 'X343', 'X235', 'X330', 'X68', 'X332', 'X221', 'X37', 'X85', 'X223', 'X27', 'X130', 'X318', 'X136', 'X26', 'X349', 'X247', 'X297', 'X98', 'X336', 'X232', 'X90', 'X281', 'X201', 'X70', 'X265', 'X127', 'X76', 'X102', 'X195', 'X366', 'X362', 'X24', 'X246', 'X106', 'X96', 'X376', 'X170', 'X350', 'X169', 'X58', 'X355', 'X328', 'X119', 'X178', 'X56', 'X299', 'X239', 'X173', 'X295', 'X274', 'X148', 'X191', 'X152', 'X208', 'X45', 'X41']\n",
      "\n",
      "Categorical = ['X2', 'X1', 'X3', 'X6', 'X4', 'X5', 'X8', 'X0']\n"
     ]
    }
   ],
   "source": [
    "original_nums, cats = get_type_lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into to train and validation (before doing data prep!!!)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2936, 378)\n",
      "(1273, 378)\n"
     ]
    }
   ],
   "source": [
    "train, valid = train.split_frame([0.7], seed=12345)\n",
    "print(train.shape)\n",
    "print(valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode categorical vars using shrunken averages\n",
    "---\n",
    "http://helios.mm.di.uoa.gr/~rouvas/ssi/sigkdd/sigkdd.vol3.1/barreca.ps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_encoder(training_frame, test_frame, x, y, lambda_=0.15, threshold=150, test=False):\n",
    "\n",
    "    \"\"\" Applies simple target encoding to categorical variables.\n",
    "\n",
    "    :param training_frame: Training frame which to create target means and to be encoded.\n",
    "    :param test_frame: Test frame to be encoded using information from training frame.\n",
    "    :param x: Name of input variable to be encoded.\n",
    "    :param y: Name of target variable to use for encoding.\n",
    "    :param lambda_: Balance between level mean and overall mean for small groups.\n",
    "    :param threshold: Number below which a level is considered small enough to be shrunken.\n",
    "    :param test: Whether or not to print the row_val_dict for testing purposes.\n",
    "    :return: Tuple of encoded variable from train and test set as H2OFrames.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # convert to pandas\n",
    "    trdf = training_frame.as_data_frame().loc[:, [x,y]] # df\n",
    "    tss = test_frame.as_data_frame().loc[:, x]          # series\n",
    "\n",
    "\n",
    "    # create dictionary of level:encode val\n",
    "\n",
    "    encode_name = x + '_Tencode'\n",
    "    overall_mean = trdf[y].mean()\n",
    "    row_val_dict = {}\n",
    "\n",
    "    for level in trdf[x].unique():\n",
    "        level_df = trdf[trdf[x] == level][y]\n",
    "        level_n = level_df.shape[0]\n",
    "        level_mean = level_df.mean()\n",
    "        if level_n >= threshold:\n",
    "            row_val_dict[level] = level_mean\n",
    "        else:\n",
    "            row_val_dict[level] = ((1 - lambda_) * level_mean) +\\\n",
    "                                  (lambda_ * overall_mean)\n",
    "\n",
    "    row_val_dict[np.nan] = overall_mean # handle missing values\n",
    "\n",
    "    if test:\n",
    "        print(row_val_dict)\n",
    "\n",
    "    # apply the transform to training data\n",
    "    trdf[encode_name] = trdf[x].apply(lambda i: row_val_dict[i])\n",
    "\n",
    "    # apply the transform to test data\n",
    "    tsdf = pd.DataFrame(columns=[x, encode_name])\n",
    "    tsdf[x] = tss\n",
    "    tsdf.loc[:, encode_name] = overall_mean # handle previously unseen values\n",
    "    # handle values that are seen in tsdf but not row_val_dict\n",
    "    for i, col_i in enumerate(tsdf[x]):\n",
    "        try:\n",
    "            row_val_dict[col_i]\n",
    "        except:\n",
    "            # a value that appeared in tsdf isn't in the row_val_dict so just\n",
    "            # make it the overall_mean\n",
    "            row_val_dict[col_i] = overall_mean\n",
    "    tsdf[encode_name] = tsdf[x].apply(lambda i: row_val_dict[i])\n",
    "\n",
    "\n",
    "    # convert back to H2O\n",
    "\n",
    "    trdf = h2o.H2OFrame(trdf[encode_name].as_matrix())\n",
    "    trdf.columns = [encode_name]\n",
    "\n",
    "    tsdf = h2o.H2OFrame(tsdf[encode_name].as_matrix())\n",
    "    tsdf.columns = [encode_name]\n",
    "\n",
    "    return (trdf, tsdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute encoding\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding: X2 (1/8) ...\n",
      "Encoding: X1 (2/8) ...\n",
      "Encoding: X3 (3/8) ...\n",
      "Encoding: X6 (4/8) ...\n",
      "Encoding: X4 (5/8) ...\n",
      "Encoding: X5 (6/8) ...\n",
      "Encoding: X8 (7/8) ...\n",
      "Encoding: X0 (8/8) ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "total = len(cats)\n",
    "for i, var in enumerate(cats):\n",
    "    \n",
    "    tr_enc, _ = target_encoder(train, test, var, 'y')\n",
    "    v_enc, ts_enc = target_encoder(valid, test, var, 'y')\n",
    "    \n",
    "    print('Encoding: ' + var + ' (' + str(i+1) + '/' + str(total) + ') ...')\n",
    "\n",
    "    train = train.cbind(tr_enc)\n",
    "    valid = valid.cbind(v_enc)\n",
    "    test = test.cbind(ts_enc)    \n",
    "    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine numerics and explore\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric = ['X282', 'X309', 'X354', 'X53', 'X125', 'X64', 'X340', 'X257', 'X44', 'X51', 'X30', 'X215', 'X278', 'X159', 'X54', 'X225', 'X363', 'X382', 'X375', 'X190', 'X385', 'X145', 'X367', 'X252', 'X383', 'X113', 'X243', 'X328', 'X129', 'X287', 'X348', 'X50', 'X65', 'X89', 'X192', 'X176', 'X10', 'X11', 'X236', 'X93', 'X244', 'X67', 'X319', 'X31', 'X171', 'X352', 'X263', 'X261', 'X302', 'X172', 'X339', 'X146', 'X63', 'X377', 'X245', 'X182', 'X62', 'X280', 'X345', 'X324', 'X298', 'X364', 'X61', 'X189', 'X249', 'X266', 'X79', 'X177', 'X207', 'X71', 'X140', 'X365', 'X308', 'X237', 'X133', 'X284', 'X267', 'X291', 'X358', 'X213', 'X161', 'X95', 'X233', 'X183', 'X380', 'X344', 'X66', 'X226', 'X162', 'X353', 'X219', 'X325', 'X346', 'X217', 'X4_Tencode', 'X123', 'X134', 'X356', 'X264', 'X314', 'X150', 'X242', 'X60', 'X57', 'X180', 'X87', 'X378', 'X32', 'X18', 'X126', 'X272', 'X155', 'X311', 'X260', 'X151', 'X323', 'X293', 'X6_Tencode', 'X212', 'X275', 'X351', 'X34', 'X256', 'X36', 'X271', 'X341', 'X370', 'X371', 'X107', 'X205', 'X78', 'X258', 'X283', 'X52', 'X203', 'X154', 'X55', 'X17', 'X241', 'X117', 'X49', 'X77', 'X103', 'X42', 'X210', 'X138', 'X200', 'X163', 'X228', 'X206', 'X197', 'X373', 'X3_Tencode', 'X101', 'X33', 'X321', 'X306', 'X69', 'X286', 'X132', 'X259', 'X254', 'X277', 'X84', 'X229', 'X120', 'X46', 'X369', 'X230', 'X158', 'X2_Tencode', 'X238', 'X144', 'X86', 'X310', 'X240', 'X74', 'X216', 'X22', 'X175', 'X184', 'X73', 'X222', 'X329', 'X374', 'X199', 'X38', 'X220', 'X379', 'X312', 'X181', 'X255', 'X211', 'X202', 'X285', 'X47', 'X108', 'X94', 'X334', 'X19', 'X305', 'X337', 'X12', 'X342', 'X301', 'X1_Tencode', 'X83', 'X164', 'X112', 'X124', 'X14', 'X110', 'X165', 'X331', 'X268', 'X122', 'X316', 'X313', 'X174', 'X338', 'X114', 'X48', 'X187', 'X198', 'X253', 'X153', 'X16', 'X91', 'X209', 'X231', 'X118', 'X160', 'X322', 'X166', 'X92', 'X194', 'X360', 'X204', 'X270', 'X111', 'X147', 'X167', 'X347', 'X262', 'X248', 'X372', 'X156', 'X186', 'X333', 'X327', 'X185', 'X368', 'X99', 'X29', 'X218', 'X137', 'X279', 'X269', 'X141', 'X361', 'X315', 'X97', 'X214', 'X288', 'X115', 'X326', 'X80', 'X289', 'X168', 'X304', 'X142', 'X43', 'X292', 'X359', 'X100', 'X135', 'X139', 'X20', 'X105', 'X179', 'X28', 'X294', 'X35', 'X273', 'X143', 'X82', 'X250', 'X81', 'X234', 'X40', 'X104', 'X0_Tencode', 'X290', 'X296', 'X300', 'X335', 'X23', 'X128', 'X157', 'X59', 'X131', 'X384', 'X307', 'X39', 'X227', 'X75', 'X88', 'X224', 'X320', 'X276', 'X317', 'X21', 'X15', 'X251', 'X116', 'X196', 'X343', 'X235', 'X330', 'X68', 'X332', 'X221', 'X37', 'X85', 'X223', 'X8_Tencode', 'X27', 'X130', 'X318', 'X136', 'X109', 'X26', 'X349', 'X247', 'X297', 'X98', 'X336', 'X232', 'X90', 'X281', 'X201', 'X70', 'X265', 'X127', 'X76', 'X102', 'X195', 'X366', 'X362', 'X24', 'X246', 'X106', 'X96', 'X376', 'X170', 'X357', 'X350', 'X13', 'X58', 'X355', 'X169', 'X5_Tencode', 'X119', 'X178', 'X56', 'X299', 'X239', 'X173', 'X295', 'X274', 'X148', 'X191', 'X152', 'X208', 'X45', 'X41']\n",
      "\n",
      "Categorical = ['X2', 'X1', 'X3', 'X6', 'X4', 'X5', 'X8', 'X0']\n"
     ]
    }
   ],
   "source": [
    "encoded_nums, cats = get_type_lists(frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create combination features\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_combiner(training_frame, test_frame, nums):\n",
    "    \n",
    "    \"\"\" Combines numeric features using simple arithmatic operations.\n",
    "    \n",
    "    :param training_frame: Training frame from which to generate features and onto which generated \n",
    "                           feeatures will be cbound.\n",
    "    :param test_frame: Test frame from which to generate features and onto which generated \n",
    "                       feeatures will be cbound.\n",
    "    :param nums: List of original numeric features from which to generate combined features.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    total = len(nums)\n",
    "    \n",
    "    # convert to pandas\n",
    "    train_df = training_frame.as_data_frame()\n",
    "    test_df = test_frame.as_data_frame()\n",
    "    \n",
    "    for i, col_i in enumerate(nums):\n",
    "        \n",
    "        print('Combining: ' + col_i + ' (' + str(i+1) + '/' + str(total) + ') ...')        \n",
    "        \n",
    "        for j, col_j in enumerate(nums):\n",
    "            \n",
    "            # don't repeat (i*j = j*i)\n",
    "            if i < j:\n",
    "                \n",
    "                # convert to pandas\n",
    "                col_i_train_df = train_df[col_i]\n",
    "                col_j_train_df = train_df[col_j]\n",
    "                col_i_test_df = test_df[col_i]\n",
    "                col_j_test_df = test_df[col_j] \n",
    "\n",
    "                # multiply, convert back to h2o\n",
    "                train_df[str(col_i + '|' + col_j)] = col_i_train_df.values*col_j_train_df.values\n",
    "                test_df[str(col_i + '|' + col_j)] = col_i_test_df.values*col_j_test_df.values\n",
    "                \n",
    "    print('Done.')\n",
    "    \n",
    "    # convert back to h2o\n",
    "    \n",
    "    print('Converting to H2OFrame ...')\n",
    "    \n",
    "    training_frame = h2o.H2OFrame(train_df)\n",
    "    training_frame.columns = list(train_df)\n",
    "    test_frame = h2o.H2OFrame(test_df)\n",
    "    test_frame.columns = list(test_df)\n",
    "    \n",
    "    print('Done.')\n",
    "    print()\n",
    "    \n",
    "    # conserve memory \n",
    "    del train_df\n",
    "    del test_df \n",
    "    \n",
    "    return training_frame, test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-35dc8908d1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_combiner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_nums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_combiner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_nums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-654cc5d63b3b>\u001b[0m in \u001b[0;36mfeature_combiner\u001b[0;34m(training_frame, test_frame, nums)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# convert to pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_data_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_data_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36mas_data_frame\u001b[0;34m(self, use_pandas, header)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcan_use_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_pandas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36mget_frame_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0mindividual\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mseparated\u001b[0m \u001b[0mby\u001b[0m \u001b[0mcommas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \"\"\"\n\u001b[0;32m-> 1251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /3/DownloadDataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"frame_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hex_string\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    398\u001b[0m             resp = requests.request(method=method, url=url, data=data, json=json, files=files, params=params,\n\u001b[1;32m    399\u001b[0m                                     \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                                     auth=self._auth, verify=self._verify_ssl_cert, proxies=self._proxies)\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    500\u001b[0m         }\n\u001b[1;32m    501\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niki/anaconda/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train, _ = feature_combiner(train, test, encoded_nums)\n",
    "valid, test = feature_combiner(valid, test, encoded_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine numerics and explore\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric = ['X282', 'X309', 'X354', 'X53', 'X125', 'X64', 'X340', 'X257', 'X44', 'X51', 'X30', 'X215', 'X278', 'X159', 'X54', 'X225', 'X363', 'X382', 'X375', 'X190', 'X385', 'X145', 'X367', 'X252', 'X383', 'X113', 'X243', 'X328', 'X129', 'X287', 'X348', 'X50', 'X65', 'X89', 'X192', 'X176', 'X10', 'X11', 'X236', 'X93', 'X244', 'X67', 'X319', 'X31', 'X171', 'X352', 'X263', 'X261', 'X302', 'X172', 'X339', 'X146', 'X63', 'X377', 'X245', 'X182', 'X62', 'X280', 'X345', 'X324', 'X298', 'X364', 'X61', 'X189', 'X249', 'X266', 'X79', 'X177', 'X207', 'X71', 'X140', 'X365', 'X308', 'X237', 'X133', 'X284', 'X267', 'X291', 'X358', 'X213', 'X161', 'X95', 'X233', 'X183', 'X380', 'X344', 'X66', 'X226', 'X162', 'X353', 'X219', 'X325', 'X346', 'X217', 'X4_Tencode', 'X123', 'X134', 'X356', 'X264', 'X314', 'X150', 'X242', 'X60', 'X57', 'X180', 'X87', 'X378', 'X32', 'X18', 'X126', 'X272', 'X155', 'X311', 'X260', 'X151', 'X323', 'X293', 'X6_Tencode', 'X212', 'X275', 'X351', 'X34', 'X256', 'X36', 'X271', 'X341', 'X370', 'X371', 'X107', 'X205', 'X78', 'X258', 'X283', 'X52', 'X203', 'X154', 'X55', 'X17', 'X241', 'X117', 'X49', 'X77', 'X103', 'X42', 'X210', 'X138', 'X200', 'X163', 'X228', 'X206', 'X197', 'X373', 'X3_Tencode', 'X101', 'X33', 'X321', 'X306', 'X69', 'X286', 'X132', 'X259', 'X254', 'X277', 'X84', 'X229', 'X120', 'X46', 'X369', 'X230', 'X158', 'X2_Tencode', 'X238', 'X144', 'X86', 'X310', 'X240', 'X74', 'X216', 'X22', 'X175', 'X184', 'X73', 'X222', 'X329', 'X374', 'X199', 'X38', 'X220', 'X379', 'X312', 'X181', 'X255', 'X211', 'X202', 'X285', 'X47', 'X108', 'X94', 'X334', 'X19', 'X305', 'X337', 'X12', 'X342', 'X301', 'X1_Tencode', 'X83', 'X164', 'X112', 'X124', 'X14', 'X110', 'X165', 'X331', 'X268', 'X122', 'X316', 'X313', 'X174', 'X338', 'X114', 'X48', 'X187', 'X198', 'X253', 'X153', 'X16', 'X91', 'X209', 'X231', 'X118', 'X160', 'X322', 'X166', 'X92', 'X194', 'X360', 'X204', 'X270', 'X111', 'X147', 'X167', 'X347', 'X262', 'X248', 'X372', 'X156', 'X186', 'X333', 'X327', 'X185', 'X368', 'X99', 'X29', 'X218', 'X137', 'X279', 'X269', 'X141', 'X361', 'X315', 'X97', 'X214', 'X288', 'X115', 'X326', 'X80', 'X289', 'X168', 'X304', 'X142', 'X43', 'X292', 'X359', 'X100', 'X135', 'X139', 'X20', 'X105', 'X179', 'X28', 'X294', 'X35', 'X273', 'X143', 'X82', 'X250', 'X81', 'X234', 'X40', 'X104', 'X0_Tencode', 'X290', 'X296', 'X300', 'X335', 'X23', 'X128', 'X157', 'X59', 'X131', 'X384', 'X307', 'X39', 'X227', 'X75', 'X88', 'X224', 'X320', 'X276', 'X317', 'X21', 'X15', 'X251', 'X116', 'X196', 'X343', 'X235', 'X330', 'X68', 'X332', 'X221', 'X37', 'X85', 'X223', 'X8_Tencode', 'X27', 'X130', 'X318', 'X136', 'X109', 'X26', 'X349', 'X247', 'X297', 'X98', 'X336', 'X232', 'X90', 'X281', 'X201', 'X70', 'X265', 'X127', 'X76', 'X102', 'X195', 'X366', 'X362', 'X24', 'X246', 'X106', 'X96', 'X376', 'X170', 'X357', 'X350', 'X13', 'X58', 'X355', 'X169', 'X5_Tencode', 'X119', 'X178', 'X56', 'X299', 'X239', 'X173', 'X295', 'X274', 'X148', 'X191', 'X152', 'X208', 'X45', 'X41']\n",
      "\n",
      "Categorical = ['X2', 'X1', 'X3', 'X6', 'X4', 'X5', 'X8', 'X0']\n"
     ]
    }
   ],
   "source": [
    "encoded_combined_nums, cats = get_type_lists(frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check number of created variables is correct\n",
    "# 1 id column, 1 target column, 58 original + encoded numeric columns, 8 original categorical variables\n",
    "# sum(range(1, 58)) combined variables\n",
    "print(train.shape == (2936, sum(range(1, 58), (58 + 8 + 1 + 1))))\n",
    "print(test.shape == (4209, sum(range(1, 58), (58 + 8 + 1 + 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check multiplication for a random column\n",
    "ridx = np.random.choice(sum(range(1, 58)))\n",
    "combined_only = [name for name in encoded_combined_nums if name not in encoded_nums]\n",
    "combined_check_vars = combined_only[ridx].split('|')\n",
    "combined_check_vars.append(combined_only[ridx])\n",
    "\n",
    "print(train[736, combined_check_vars])\n",
    "print(test[637, combined_check_vars])\n",
    "\n",
    "print(train[736, combined_check_vars[0]]*train[736, combined_check_vars[1]])\n",
    "print(test[637, combined_check_vars[0]]*test[637, combined_check_vars[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o.show_progress() # turn on progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check log transform - looks good\n",
    "%matplotlib inline\n",
    "train['y'].log().as_data_frame().hist()\n",
    "\n",
    "# Execute log transform\n",
    "train['y'] = train['y'].log()\n",
    "valid['y'] = valid['y'].log()\n",
    "print(train[0:3, 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define ranked predictions plot function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ranked_preds_plot(y, valid, preds):\n",
    "    \n",
    "    \"\"\" Generates ranked prediction plot.\n",
    "    \n",
    "    :param y: Name of target variable.\n",
    "    :param valid: Name of validation H2OFrame.\n",
    "    :param preds: Column vector of predictions to plot.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # plot top frame values\n",
    "    preds.columns = ['predict']\n",
    "    yhat_frame = valid.cbind(preds)\n",
    "    print(yhat_frame[0:10, [y, 'predict']])\n",
    "\n",
    "    # plot sorted predictions\n",
    "    yhat_frame_df = yhat_frame[[y, 'predict']].as_data_frame()\n",
    "    yhat_frame_df.sort_values(by='predict', inplace=True)\n",
    "    yhat_frame_df.reset_index(inplace=True, drop=True)\n",
    "    _ = yhat_frame_df.plot(title='Ranked Predictions Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate submission file \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "def gen_submission(preds, test=test):\n",
    "\n",
    "    \"\"\" Generates submission file for Kaggle House Prices contest.\n",
    "    \n",
    "    :param preds: Column vector of predictions.\n",
    "    :param test: Test data.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # create time stamp\n",
    "    time_stamp = re.sub('[: ]', '_', time.asctime())\n",
    "\n",
    "    # create predictions column\n",
    "    sub = test['ID'].cbind(preds.exp())\n",
    "    sub.columns = ['ID', 'y']\n",
    "    \n",
    "    # save file for submission\n",
    "    sub_fname = '../data/submission_' + str(time_stamp) + '.csv'\n",
    "    h2o.download_csv(sub, sub_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple prediction blending function \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def pred_blender(dir_, files):\n",
    "    \n",
    "    \"\"\" Performs simple blending of prediction files. \n",
    "    \n",
    "    :param dir_: Directory in which files to be read are stored.\n",
    "    :param files: List of prediction files to be blended.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # read predictions in files list and cbind\n",
    "    for i, file in enumerate(files):\n",
    "        if i == 0:\n",
    "            df = pd.read_csv(dir_ + os.sep + file).drop('y', axis=1)\n",
    "        col = pd.read_csv(dir_ + os.sep + file).drop('ID', axis=1)\n",
    "        col.columns = ['y' + str(i)]\n",
    "        df = pd.concat([df, col], axis=1)\n",
    "        \n",
    "    # create mean prediction    \n",
    "    df['mean'] = df.iloc[:, 1:].mean(axis=1)\n",
    "    print(df.head())\n",
    "        \n",
    "    # create time stamp\n",
    "    time_stamp = re.sub('[: ]', '_', time.asctime())        \n",
    "        \n",
    "    # write new submission file    \n",
    "    df = df[['ID', 'mean']]\n",
    "    df.columns = ['ID', 'y']\n",
    "    \n",
    "    # save file for submission\n",
    "    sub_fname = '../data/submission_' + str(time_stamp) + '.csv'\n",
    "    df.to_csv(sub_fname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest model - typically not tuned as much as GBM\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize rf model\n",
    "rf_model1 = H2ORandomForestEstimator(\n",
    "    ntrees=10000,                    \n",
    "    max_depth=10, \n",
    "    col_sample_rate_per_tree=0.1,\n",
    "    sample_rate=0.8,\n",
    "    stopping_rounds=50,\n",
    "    score_each_iteration=True,\n",
    "    nfolds=3,\n",
    "    keep_cross_validation_predictions=True,\n",
    "    seed=12345)           \n",
    "\n",
    "# train rf model\n",
    "rf_model1.train(\n",
    "    x=encoded_combined_nums,\n",
    "    y='y',\n",
    "    training_frame=train,\n",
    "    validation_frame=valid)\n",
    "\n",
    "# print model information\n",
    "print(rf_model1)\n",
    "\n",
    "rf_preds1_val = rf_model1.predict(valid)\n",
    "ranked_preds_plot('y', valid, rf_preds1_val) # valid RMSE not so hot ...\n",
    "rf_preds1_test = rf_model1.predict(test)\n",
    "gen_submission(rf_preds1_test) # public leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extremely random trees model - typically not tuned as much as GBM\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize extra trees model\n",
    "ert_model1 = H2ORandomForestEstimator(\n",
    "    ntrees=10000,                    \n",
    "    max_depth=10, \n",
    "    col_sample_rate_per_tree=0.1,\n",
    "    sample_rate=0.8,\n",
    "    stopping_rounds=50,\n",
    "    score_each_iteration=True,\n",
    "    nfolds=3,\n",
    "    keep_cross_validation_predictions=True,\n",
    "    seed=12345,\n",
    "    histogram_type='random') # <- this is what makes it ERT instead of RF\n",
    "\n",
    "# train ert model\n",
    "ert_model1.train(\n",
    "    x=encoded_combined_nums,\n",
    "    y='y',\n",
    "    training_frame=train,\n",
    "    validation_frame=valid)\n",
    "\n",
    "# print model information/create submission\n",
    "print(ert_model1)\n",
    "ert_preds1_val = ert_model1.predict(valid)\n",
    "ranked_preds_plot('y', valid, ert_preds1_val) # valid RMSE not so hot ...\n",
    "ert_preds1_test = ert_model1.predict(test)\n",
    "gen_submission(ert_preds1_test) #  public leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2O GBM model\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize H2O GBM\n",
    "h2o_gbm_model = H2OGradientBoostingEstimator(\n",
    "    ntrees = 10000,\n",
    "    learn_rate = 0.005,\n",
    "    sample_rate = 0.1, \n",
    "    col_sample_rate = 0.8,\n",
    "    max_depth = 5,\n",
    "    nfolds = 3,\n",
    "    keep_cross_validation_predictions=True,\n",
    "    stopping_rounds = 10,\n",
    "    seed = 12345)\n",
    "\n",
    "# execute training\n",
    "h2o_gbm_model.train(x=encoded_combined_nums,\n",
    "                    y='y',\n",
    "                    training_frame=train,\n",
    "                    validation_frame=valid)\n",
    "\n",
    "# print model information/create submission\n",
    "print(h2o_gbm_model)\n",
    "h2o_gbm_preds1_val = h2o_gbm_model.predict(valid)\n",
    "ranked_preds_plot('y', valid, h2o_gbm_preds1_val) # better validation error\n",
    "h2o_gbm_preds1_test = h2o_gbm_model.predict(test)\n",
    "gen_submission(h2o_gbm_preds1_test) #  public leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train H2O XGBoost - very new!!\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize XGB GBM\n",
    "h2o_xgb_model = H2OXGBoostEstimator(\n",
    "    ntrees = 10000,\n",
    "    learn_rate = 0.005,\n",
    "    sample_rate = 0.1, \n",
    "    col_sample_rate = 0.8,\n",
    "    max_depth = 5,\n",
    "    nfolds = 3,\n",
    "    keep_cross_validation_predictions=True,\n",
    "    stopping_rounds = 10,\n",
    "    seed = 12345)\n",
    "\n",
    "# execute training \n",
    "h2o_xgb_model.train(x=encoded_combined_nums,\n",
    "                    y='y',\n",
    "                    training_frame=train,\n",
    "                    validation_frame=valid)\n",
    "\n",
    "# print model information/create submission\n",
    "print(h2o_xgb_model)\n",
    "h2o_xgb_preds1_val = h2o_xgb_model.predict(valid)\n",
    "ranked_preds_plot('y', valid, h2o_xgb_preds1_val) \n",
    "h2o_xgb_preds1_test = h2o_xgb_model.predict(test)\n",
    "gen_submission(h2o_xgb_preds1_test) #  on public leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create blend\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create XGBoost blend\n",
    "pred_blender('../data',\n",
    "            [''])\n",
    "#  on public leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train H2O stacked model \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = H2OStackedEnsembleEstimator(training_frame=train, \n",
    "                                    validation_frame=valid, \n",
    "                                    base_models=[rf_model1, ert_model1, \n",
    "                                                 h2o_gbm_model])\n",
    "\n",
    "stack.train(x=encoded_combined_nums,\n",
    "            y='y',\n",
    "            training_frame=train,\n",
    "            validation_frame=valid)\n",
    "\n",
    "# print model information/create submission\n",
    "print(stack)\n",
    "stack_preds1_val = stack.predict(valid)\n",
    "ranked_preds_plot('y', valid, stack_preds1_val) \n",
    "stack_preds1_test = stack.predict(test)\n",
    "gen_submission(stack_preds1_test)\n",
    "#  on public leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shutdown H2O\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shutdown H2O - this will erase all your unsaved frames and models in H2O\n",
    "h2o.cluster().shutdown(prompt=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
